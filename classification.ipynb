{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\faizaan09\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pickle as pkl\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import optimizers\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "# from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error,make_scorer\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"./data/umm_balanced.pkl\",\"rb\") as pk:\n",
    "    features, labels = pkl.load(pk)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.20, random_state = 42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "sc_train = scaler.transform(X_train)\n",
    "sc_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/100\n",
      "3200/3200 [==============================] - 2s 640us/step - loss: 0.6724 - acc: 0.6303 - val_loss: 0.6039 - val_acc: 0.6837\n",
      "Epoch 2/100\n",
      "3200/3200 [==============================] - 1s 418us/step - loss: 0.5640 - acc: 0.7109 - val_loss: 0.5582 - val_acc: 0.7300\n",
      "Epoch 3/100\n",
      "3200/3200 [==============================] - 2s 587us/step - loss: 0.5326 - acc: 0.7366 - val_loss: 0.5557 - val_acc: 0.7175\n",
      "Epoch 4/100\n",
      "3200/3200 [==============================] - 1s 465us/step - loss: 0.5207 - acc: 0.7406 - val_loss: 0.5453 - val_acc: 0.7325\n",
      "Epoch 5/100\n",
      "3200/3200 [==============================] - 1s 435us/step - loss: 0.5011 - acc: 0.7522 - val_loss: 0.5397 - val_acc: 0.7400\n",
      "Epoch 6/100\n",
      "3200/3200 [==============================] - 1s 427us/step - loss: 0.4769 - acc: 0.7622 - val_loss: 0.5512 - val_acc: 0.7488\n",
      "Epoch 7/100\n",
      "3200/3200 [==============================] - 1s 434us/step - loss: 0.4456 - acc: 0.7800 - val_loss: 0.5033 - val_acc: 0.7538\n",
      "Epoch 8/100\n",
      "3200/3200 [==============================] - 1s 421us/step - loss: 0.4222 - acc: 0.7963 - val_loss: 0.5296 - val_acc: 0.7388\n",
      "Epoch 9/100\n",
      "3200/3200 [==============================] - 2s 471us/step - loss: 0.4033 - acc: 0.8153 - val_loss: 0.5149 - val_acc: 0.7500\n",
      "Epoch 10/100\n",
      "3200/3200 [==============================] - 2s 502us/step - loss: 0.3653 - acc: 0.8325 - val_loss: 0.5420 - val_acc: 0.7662\n",
      "Epoch 11/100\n",
      "3200/3200 [==============================] - 1s 467us/step - loss: 0.3388 - acc: 0.8425 - val_loss: 0.5074 - val_acc: 0.8063\n",
      "Epoch 12/100\n",
      "3200/3200 [==============================] - 2s 511us/step - loss: 0.3176 - acc: 0.8547 - val_loss: 0.5163 - val_acc: 0.7688\n",
      "Epoch 13/100\n",
      "3200/3200 [==============================] - 2s 606us/step - loss: 0.2781 - acc: 0.8731 - val_loss: 0.4820 - val_acc: 0.7837\n",
      "Epoch 14/100\n",
      "3200/3200 [==============================] - 2s 586us/step - loss: 0.2560 - acc: 0.8875 - val_loss: 0.5293 - val_acc: 0.7887\n",
      "Epoch 15/100\n",
      "3200/3200 [==============================] - 2s 572us/step - loss: 0.2386 - acc: 0.8956 - val_loss: 0.5285 - val_acc: 0.8050\n",
      "Epoch 16/100\n",
      "3200/3200 [==============================] - 2s 609us/step - loss: 0.2139 - acc: 0.9100 - val_loss: 0.5469 - val_acc: 0.8013\n",
      "Epoch 17/100\n",
      "3200/3200 [==============================] - 2s 506us/step - loss: 0.1859 - acc: 0.9228 - val_loss: 0.6348 - val_acc: 0.7950\n",
      "Epoch 18/100\n",
      "3200/3200 [==============================] - 1s 426us/step - loss: 0.1679 - acc: 0.9300 - val_loss: 0.5918 - val_acc: 0.8063\n",
      "Epoch 19/100\n",
      "3200/3200 [==============================] - 1s 434us/step - loss: 0.1522 - acc: 0.9391 - val_loss: 0.6247 - val_acc: 0.8063\n",
      "Epoch 20/100\n",
      "3200/3200 [==============================] - 1s 466us/step - loss: 0.1358 - acc: 0.9450 - val_loss: 0.6196 - val_acc: 0.8075\n",
      "Epoch 21/100\n",
      "3200/3200 [==============================] - 1s 461us/step - loss: 0.1214 - acc: 0.9550 - val_loss: 0.6900 - val_acc: 0.8137\n",
      "Epoch 22/100\n",
      "3200/3200 [==============================] - 2s 477us/step - loss: 0.1026 - acc: 0.9603 - val_loss: 0.7545 - val_acc: 0.8025\n",
      "Epoch 23/100\n",
      "3200/3200 [==============================] - 2s 474us/step - loss: 0.1307 - acc: 0.9481 - val_loss: 0.7604 - val_acc: 0.8063\n",
      "Epoch 24/100\n",
      "3200/3200 [==============================] - 1s 466us/step - loss: 0.0937 - acc: 0.9622 - val_loss: 0.7148 - val_acc: 0.8037\n",
      "Epoch 25/100\n",
      "3200/3200 [==============================] - 2s 532us/step - loss: 0.0754 - acc: 0.9734 - val_loss: 0.7885 - val_acc: 0.8137\n",
      "Epoch 26/100\n",
      "3200/3200 [==============================] - 1s 463us/step - loss: 0.0748 - acc: 0.9741 - val_loss: 0.7909 - val_acc: 0.7975\n",
      "Epoch 27/100\n",
      "3200/3200 [==============================] - 1s 463us/step - loss: 0.0644 - acc: 0.9731 - val_loss: 0.7953 - val_acc: 0.8163\n",
      "Epoch 28/100\n",
      "3200/3200 [==============================] - 1s 453us/step - loss: 0.0701 - acc: 0.9759 - val_loss: 0.9436 - val_acc: 0.8150\n",
      "Epoch 29/100\n",
      "3200/3200 [==============================] - 1s 448us/step - loss: 0.0612 - acc: 0.9781 - val_loss: 0.8298 - val_acc: 0.8325\n",
      "Epoch 30/100\n",
      "3200/3200 [==============================] - 1s 441us/step - loss: 0.0441 - acc: 0.9819 - val_loss: 0.9302 - val_acc: 0.8087\n",
      "Epoch 31/100\n",
      "3200/3200 [==============================] - 2s 537us/step - loss: 0.0499 - acc: 0.9844 - val_loss: 0.8320 - val_acc: 0.8200\n",
      "Epoch 32/100\n",
      "3200/3200 [==============================] - 1s 428us/step - loss: 0.0441 - acc: 0.9841 - val_loss: 0.8454 - val_acc: 0.8400\n",
      "Epoch 33/100\n",
      "3200/3200 [==============================] - 1s 451us/step - loss: 0.0381 - acc: 0.9866 - val_loss: 0.9732 - val_acc: 0.8237\n",
      "Epoch 34/100\n",
      "3200/3200 [==============================] - 1s 425us/step - loss: 0.0382 - acc: 0.9872 - val_loss: 0.9590 - val_acc: 0.8287\n",
      "Epoch 35/100\n",
      "3200/3200 [==============================] - 1s 421us/step - loss: 0.0277 - acc: 0.9906 - val_loss: 0.9478 - val_acc: 0.8350\n",
      "Epoch 36/100\n",
      "3200/3200 [==============================] - 1s 425us/step - loss: 0.0292 - acc: 0.9897 - val_loss: 1.0307 - val_acc: 0.8263\n",
      "Epoch 37/100\n",
      "3200/3200 [==============================] - 1s 427us/step - loss: 0.0304 - acc: 0.9891 - val_loss: 0.9613 - val_acc: 0.8237\n",
      "Epoch 38/100\n",
      "3200/3200 [==============================] - 1s 425us/step - loss: 0.0410 - acc: 0.9853 - val_loss: 0.9724 - val_acc: 0.8375\n",
      "Epoch 39/100\n",
      "3200/3200 [==============================] - 1s 437us/step - loss: 0.0248 - acc: 0.9912 - val_loss: 0.9539 - val_acc: 0.8313\n",
      "Epoch 40/100\n",
      "3200/3200 [==============================] - 1s 439us/step - loss: 0.0377 - acc: 0.9894 - val_loss: 1.0343 - val_acc: 0.8438\n",
      "Epoch 41/100\n",
      "3200/3200 [==============================] - 1s 440us/step - loss: 0.0310 - acc: 0.9887 - val_loss: 0.9913 - val_acc: 0.8375\n",
      "Epoch 42/100\n",
      "3200/3200 [==============================] - 1s 441us/step - loss: 0.0265 - acc: 0.9909 - val_loss: 1.0012 - val_acc: 0.8375\n",
      "Epoch 43/100\n",
      "3200/3200 [==============================] - 1s 441us/step - loss: 0.0187 - acc: 0.9944 - val_loss: 1.0207 - val_acc: 0.8337\n",
      "Epoch 44/100\n",
      "3200/3200 [==============================] - 1s 441us/step - loss: 0.0220 - acc: 0.9925 - val_loss: 1.0580 - val_acc: 0.8287\n",
      "Epoch 45/100\n",
      "3200/3200 [==============================] - 1s 450us/step - loss: 0.0205 - acc: 0.9938 - val_loss: 1.0572 - val_acc: 0.8250\n",
      "Epoch 46/100\n",
      "3200/3200 [==============================] - 1s 443us/step - loss: 0.0211 - acc: 0.9928 - val_loss: 1.1378 - val_acc: 0.8400\n",
      "Epoch 47/100\n",
      "3200/3200 [==============================] - 1s 441us/step - loss: 0.0325 - acc: 0.9869 - val_loss: 1.1776 - val_acc: 0.8250\n",
      "Epoch 48/100\n",
      "3200/3200 [==============================] - 1s 445us/step - loss: 0.0293 - acc: 0.9909 - val_loss: 1.1186 - val_acc: 0.8263\n",
      "Epoch 49/100\n",
      "3200/3200 [==============================] - 1s 445us/step - loss: 0.0132 - acc: 0.9959 - val_loss: 1.0263 - val_acc: 0.8425\n",
      "Epoch 50/100\n",
      "3200/3200 [==============================] - 1s 444us/step - loss: 0.0082 - acc: 0.9975 - val_loss: 1.1521 - val_acc: 0.8313\n",
      "Epoch 51/100\n",
      "3200/3200 [==============================] - 1s 438us/step - loss: 0.0069 - acc: 0.9981 - val_loss: 1.2222 - val_acc: 0.8413\n",
      "Epoch 52/100\n",
      "3200/3200 [==============================] - 1s 464us/step - loss: 0.0151 - acc: 0.9950 - val_loss: 1.1271 - val_acc: 0.8275\n",
      "Epoch 53/100\n",
      "3200/3200 [==============================] - 1s 440us/step - loss: 0.0284 - acc: 0.9916 - val_loss: 0.9783 - val_acc: 0.8525\n",
      "Epoch 54/100\n",
      "3200/3200 [==============================] - 1s 449us/step - loss: 0.0149 - acc: 0.9947 - val_loss: 1.0970 - val_acc: 0.8375\n",
      "Epoch 55/100\n",
      "3200/3200 [==============================] - 1s 450us/step - loss: 0.0145 - acc: 0.9947 - val_loss: 1.1630 - val_acc: 0.8350\n",
      "Epoch 56/100\n",
      "3200/3200 [==============================] - 1s 441us/step - loss: 0.0137 - acc: 0.9941 - val_loss: 1.0980 - val_acc: 0.8387\n",
      "Epoch 57/100\n",
      "3200/3200 [==============================] - 1s 447us/step - loss: 0.0293 - acc: 0.9912 - val_loss: 1.0715 - val_acc: 0.8225\n",
      "Epoch 58/100\n",
      "3200/3200 [==============================] - 1s 458us/step - loss: 0.0174 - acc: 0.9950 - val_loss: 1.1055 - val_acc: 0.8325\n",
      "Epoch 59/100\n",
      "3200/3200 [==============================] - 1s 462us/step - loss: 0.0106 - acc: 0.9966 - val_loss: 1.1406 - val_acc: 0.8275\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3200 [==============================] - 1s 447us/step - loss: 0.0124 - acc: 0.9959 - val_loss: 1.1322 - val_acc: 0.8450\n",
      "Epoch 61/100\n",
      "3200/3200 [==============================] - 1s 436us/step - loss: 0.0114 - acc: 0.9956 - val_loss: 1.0956 - val_acc: 0.8500\n",
      "Epoch 62/100\n",
      "3200/3200 [==============================] - 1s 437us/step - loss: 0.0070 - acc: 0.9978 - val_loss: 1.2484 - val_acc: 0.8300\n",
      "Epoch 63/100\n",
      "3200/3200 [==============================] - 1s 427us/step - loss: 0.0061 - acc: 0.9972 - val_loss: 1.1620 - val_acc: 0.8438\n",
      "Epoch 64/100\n",
      "3200/3200 [==============================] - 1s 441us/step - loss: 0.0085 - acc: 0.9963 - val_loss: 1.3146 - val_acc: 0.8287\n",
      "Epoch 65/100\n",
      "3200/3200 [==============================] - 1s 436us/step - loss: 0.0355 - acc: 0.9900 - val_loss: 1.1197 - val_acc: 0.8225\n",
      "Epoch 66/100\n",
      "3200/3200 [==============================] - 1s 433us/step - loss: 0.0397 - acc: 0.9853 - val_loss: 1.1121 - val_acc: 0.8337\n",
      "Epoch 67/100\n",
      "3200/3200 [==============================] - 1s 432us/step - loss: 0.0151 - acc: 0.9950 - val_loss: 1.1877 - val_acc: 0.8213\n",
      "Epoch 68/100\n",
      "3200/3200 [==============================] - 1s 441us/step - loss: 0.0107 - acc: 0.9972 - val_loss: 1.3282 - val_acc: 0.8200\n",
      "Epoch 69/100\n",
      "3200/3200 [==============================] - 1s 453us/step - loss: 0.0296 - acc: 0.9909 - val_loss: 1.2501 - val_acc: 0.8213\n",
      "Epoch 70/100\n",
      "3200/3200 [==============================] - 1s 446us/step - loss: 0.0105 - acc: 0.9966 - val_loss: 1.3509 - val_acc: 0.8100\n",
      "Epoch 71/100\n",
      "3200/3200 [==============================] - 1s 455us/step - loss: 0.0176 - acc: 0.9919 - val_loss: 1.1727 - val_acc: 0.8462\n",
      "Epoch 72/100\n",
      "3200/3200 [==============================] - 1s 441us/step - loss: 0.0116 - acc: 0.9966 - val_loss: 1.2482 - val_acc: 0.8375\n",
      "Epoch 73/100\n",
      "3200/3200 [==============================] - 1s 434us/step - loss: 0.0086 - acc: 0.9975 - val_loss: 1.2384 - val_acc: 0.8313\n",
      "Epoch 74/100\n",
      "3200/3200 [==============================] - 1s 465us/step - loss: 0.0082 - acc: 0.9981 - val_loss: 1.1560 - val_acc: 0.8350\n",
      "Epoch 75/100\n",
      "3200/3200 [==============================] - 2s 526us/step - loss: 0.0089 - acc: 0.9975 - val_loss: 1.2552 - val_acc: 0.8325\n",
      "Epoch 76/100\n",
      "3200/3200 [==============================] - 2s 554us/step - loss: 0.0084 - acc: 0.9975 - val_loss: 1.2232 - val_acc: 0.8237\n",
      "Epoch 77/100\n",
      "3200/3200 [==============================] - 2s 503us/step - loss: 0.0121 - acc: 0.9956 - val_loss: 1.2359 - val_acc: 0.8313\n",
      "Epoch 78/100\n",
      "3200/3200 [==============================] - 1s 445us/step - loss: 0.0073 - acc: 0.9972 - val_loss: 1.4609 - val_acc: 0.8275\n",
      "Epoch 79/100\n",
      "3200/3200 [==============================] - 2s 485us/step - loss: 0.0158 - acc: 0.9947 - val_loss: 1.2776 - val_acc: 0.8337\n",
      "Epoch 80/100\n",
      "3200/3200 [==============================] - 2s 500us/step - loss: 0.0286 - acc: 0.9894 - val_loss: 1.2242 - val_acc: 0.8413\n",
      "Epoch 81/100\n",
      "3200/3200 [==============================] - 2s 470us/step - loss: 0.0137 - acc: 0.9956 - val_loss: 1.2885 - val_acc: 0.8438\n",
      "Epoch 82/100\n",
      "3200/3200 [==============================] - 2s 492us/step - loss: 0.0063 - acc: 0.9975 - val_loss: 1.3038 - val_acc: 0.8300\n",
      "Epoch 83/100\n",
      "3200/3200 [==============================] - 2s 514us/step - loss: 0.0093 - acc: 0.9969 - val_loss: 1.4238 - val_acc: 0.8225\n",
      "Epoch 84/100\n",
      "3200/3200 [==============================] - 2s 556us/step - loss: 0.0069 - acc: 0.9969 - val_loss: 1.3123 - val_acc: 0.8325\n",
      "Epoch 85/100\n",
      "3200/3200 [==============================] - 2s 530us/step - loss: 0.0073 - acc: 0.9966 - val_loss: 1.2409 - val_acc: 0.8475\n",
      "Epoch 86/100\n",
      "3200/3200 [==============================] - 2s 481us/step - loss: 0.0138 - acc: 0.9963 - val_loss: 1.3489 - val_acc: 0.8175\n",
      "Epoch 87/100\n",
      "3200/3200 [==============================] - 2s 545us/step - loss: 0.0261 - acc: 0.9934 - val_loss: 1.4474 - val_acc: 0.8100\n",
      "Epoch 88/100\n",
      "3200/3200 [==============================] - 2s 522us/step - loss: 0.0332 - acc: 0.9897 - val_loss: 1.0646 - val_acc: 0.8275\n",
      "Epoch 89/100\n",
      "3200/3200 [==============================] - 2s 518us/step - loss: 0.0073 - acc: 0.9969 - val_loss: 1.0382 - val_acc: 0.8588\n",
      "Epoch 90/100\n",
      "3200/3200 [==============================] - 2s 491us/step - loss: 0.0208 - acc: 0.9938 - val_loss: 1.2797 - val_acc: 0.8050\n",
      "Epoch 91/100\n",
      "3200/3200 [==============================] - 2s 503us/step - loss: 0.0082 - acc: 0.9966 - val_loss: 1.1721 - val_acc: 0.8438\n",
      "Epoch 92/100\n",
      "3200/3200 [==============================] - 2s 576us/step - loss: 0.0041 - acc: 0.9988 - val_loss: 1.3548 - val_acc: 0.8175\n",
      "Epoch 93/100\n",
      "3200/3200 [==============================] - 2s 532us/step - loss: 0.0026 - acc: 0.9984 - val_loss: 1.2118 - val_acc: 0.8350\n",
      "Epoch 94/100\n",
      "3200/3200 [==============================] - 2s 498us/step - loss: 0.0023 - acc: 0.9984 - val_loss: 1.2946 - val_acc: 0.8263\n",
      "Epoch 95/100\n",
      "3200/3200 [==============================] - 2s 490us/step - loss: 0.0035 - acc: 0.9988 - val_loss: 1.1768 - val_acc: 0.8488\n",
      "Epoch 96/100\n",
      "3200/3200 [==============================] - 2s 504us/step - loss: 0.0076 - acc: 0.9978 - val_loss: 1.1687 - val_acc: 0.8500\n",
      "Epoch 97/100\n",
      "3200/3200 [==============================] - 2s 487us/step - loss: 0.0096 - acc: 0.9972 - val_loss: 1.2996 - val_acc: 0.8325\n",
      "Epoch 98/100\n",
      "3200/3200 [==============================] - 2s 495us/step - loss: 0.0137 - acc: 0.9953 - val_loss: 1.2734 - val_acc: 0.8387\n",
      "Epoch 99/100\n",
      "3200/3200 [==============================] - 2s 517us/step - loss: 0.0380 - acc: 0.9903 - val_loss: 1.2322 - val_acc: 0.8325\n",
      "Epoch 100/100\n",
      "3200/3200 [==============================] - 2s 491us/step - loss: 0.0205 - acc: 0.9934 - val_loss: 1.2968 - val_acc: 0.8200\n",
      "800/800 [==============================] - 0s 82us/step\n",
      "[1.2967656528949738, 0.82]\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "n_dim = X_train.shape[1]\n",
    "n_hidden_units_one = 400\n",
    "n_hidden_units_two = 800\n",
    "sd = 1 / np.sqrt(n_dim)\n",
    "learning_rate = 0.002\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(n_hidden_units_one, input_shape = (n_dim,), kernel_initializer = keras.initializers.RandomNormal(mean=0, stddev=sd)),\n",
    "    Activation('sigmoid'),\n",
    "    Dense(n_hidden_units_two, kernel_initializer = keras.initializers.RandomNormal(mean=0, stddev=sd)),\n",
    "    Activation('sigmoid'),\n",
    "    Dense(1),\n",
    "    Activation('sigmoid')\n",
    "])\n",
    "adam = optimizers.Nadam(lr=learning_rate)# Adam(lr=learning_rate)\n",
    "model.compile(optimizer = adam, loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(sc_train,y_train,epochs = epochs, batch_size = 32, validation_data=(sc_test,y_test))\n",
    "\n",
    "score = model.evaluate(sc_test,y_test, batch_size = 32)\n",
    "print (score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\faizaan09\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.88\n"
     ]
    }
   ],
   "source": [
    "# svc = svm.SVC()\n",
    "\n",
    "# svc_params = {'kernel':('rbf','linear','poly', 'sigmoid'),'C': [0.1,1,10], 'tol' : [1e-3,1e-6]} \n",
    "\n",
    "# svc = GridSearchCV(svm.SVC(), svc_params, scoring = 'accuracy', n_jobs = 8,cv = 5, verbose=1)\n",
    "\n",
    "svc = svm.SVC(kernel='rbf', C = 10, tol=1e-1, gamma = 0.1,max_iter=1200)\n",
    "\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "print(metrics.accuracy_score(svc.predict(X_train), y_train), metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(kernel='rbf', C = 10, tol=1e-9, gamma = 0.1)\n",
    "1.0 0.88125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "rf_params = {'n_estimators' : [200,300,400],'max_depth':[100,150,300]}\n",
    "\n",
    "rf = GridSearchCV(RandomForestClassifier(n_jobs=-1), rf_params, scoring = 'accuracy', n_jobs = 1,cv = 5, verbose=1)\n",
    "\n",
    "# rf = RandomForestClassifier(n_estimators=100, max_depth=20, n_jobs=-1)\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(metrics.accuracy_score(rf.predict(X_train), y_train), metrics.accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=100, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 270 out of 270 | elapsed: 18.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.8175\n"
     ]
    }
   ],
   "source": [
    "\n",
    "knn_params = {'n_neighbors': [10,20,50], 'weights': ('uniform','distance'), \n",
    "              'algorithm' :('ball_tree', 'kd_tree', 'brute'),\n",
    "              'p': [1,2,3]\n",
    "             }\n",
    "\n",
    "neigh = GridSearchCV(KNN(n_jobs=-1), knn_params, scoring = 'accuracy', n_jobs = 1,cv = 5, verbose=1)\n",
    "\n",
    "neigh.fit(X_train, y_train) \n",
    "\n",
    "y_pred = neigh.predict(X_test)\n",
    "print(metrics.accuracy_score(neigh.predict(X_train), y_train), metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=-1, n_neighbors=50, p=1,\n",
       "           weights='distance')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
